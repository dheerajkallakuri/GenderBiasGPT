# GenderBiasGPT

GenderBiasGPT is a tool designed to detect gender bias in text inputs, specifically for non-English languages like Vietnamese and Hindi. This model assesses whether a sentence is biased toward a male or female perspective and provides a bias score ranging from 0 to 1.

## Inspiration
Our inspiration comes from the need to detect gender bias in languages other than English. While there are some models available to analyze bias in English text, few tools are dedicated to regional languages. GenderBiasGPT fills this gap by providing a model that identifies gender bias in sentences written in Vietnamese or Hindi.

## What it Does
GenderBiasGPT evaluates text inputs in Vietnamese or Hindi and scores them on a scale of 0 to 1, indicating the level of bias toward a male or female perspective. This score provides insight into how strongly a sentence may be biased in a particular direction.

## How We Built It
Our model leverages a regression architecture to detect gender bias within the input language. Key components include:
- **Tokenization and Embedding:** We tokenize the input text, generating embeddings that capture contextual meaning.
- **Gender Subspace Definition:** Using a gender subspace we defined, the model evaluates how the tokens in a sentence align with male or female bias, ultimately generating a bias score through cosine similarity.

## Challenges We Faced
Finding an accurate model for tokenization, especially for Vietnamese and Hindi, presented challenges. Each language requires a distinct approach to capture the nuances that indicate gender bias.

## Accomplishments We're Proud Of
- Successfully defining a **gender subspace** to analyze bias.
- Achieving an **accuracy of around 70%** in bias detection.
- Developing an **interactive output** that displays the bias score in a user-friendly way.

## What We Learned
We explored the nuances of implementing a gender bias model, especially in adapting concepts from English-language models to regional languages. Experimenting with various language models helped us understand the complexities of multi-language bias detection.

## What's Next for GenderBiasGPT
- **Scaling to other languages** and adding support for additional regional dialects.
- Expanding detection to other forms of bias, including **social, political, and racial** biases.
- Working to **increase accuracy** and enhance the user experience.

GenderBiasGPT is an exciting first step toward making bias detection tools accessible for a wider range of languages and perspectives. We look forward to expanding and improving our model!

---

## Setup Guide

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/dheerajkallakuri/GenderBiasGPT
   cd GenderBiasGPT
   ```

2. **Install Dependencies**:
   Make sure you have `pip` installed, then run:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the Application**:
   Open two terminal windows:

   - **Terminal 1** (Frontend):
     ```bash
     streamlit run gui.py
     ```
   
   - **Terminal 2** (Backend):
     ```bash
     python3 app.py
     ```

4. **Information**:
   The backend is built with Flask, the frontend is built on streamlit while the bias score is generated by a regression model that uses cosine similarity to evaluate gender bias in the text.

---

## Links

- **Presentation Link**: [https://docs.google.com/presentation/d/1gW6mgpVI6ElJAMt6ORozUrit6j601suvUXyPaN7WVYg/edit?usp=sharing]
- **Devpost Link**: [https://devpost.com/software/genderbiasgpt-for-regional-languages]
- **Demo Video Link**: [Add Video Link Here]

---
